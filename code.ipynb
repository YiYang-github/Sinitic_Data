{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file: **only** involves calculating storage-needed weights, not for plotting\n",
    "- 1. Generating distance matrix from raw transcription (for Yubao), and select parts of dialects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data4_dir, data4_dir_matrix = 'Data4/transcription_areas.pkl', 'Data4/distance_matrices.npz'\n",
    "\n",
    "def list_available_data():\n",
    "    \"\"\"\n",
    "    列出可用的数据集及其包含的特征\n",
    "    \"\"\"\n",
    "    available_data = {\n",
    "        'Data4': {\n",
    "            'description': '中国语言资源保护工程',\n",
    "            'features': [\n",
    "                'word_name', 'area', 'slice', 'slices', 'coords',\n",
    "                'initial', 'final', 'tone',\n",
    "                'initials_distance', 'finals_distance', 'tones_distance', 'overall_distance'\n",
    "            ]\n",
    "        }\n",
    "        # 可以添加其他数据集\n",
    "    }\n",
    "    return available_data\n",
    "\n",
    "def load_feats(name, features=None):\n",
    "    \"\"\"\n",
    "    加载指定数据集的指定特征\n",
    "\n",
    "    Args:\n",
    "        name (str): 数据集名称 (e.g., 'Data4')\n",
    "        features (list, optional): 需要加载的特征列表.\n",
    "                                     如果为None，则加载所有特征. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含请求特征的字典\n",
    "    \"\"\"\n",
    "    loaded_data = {}\n",
    "\n",
    "    if name == 'Data4':\n",
    "        all_features = [\n",
    "            'word_name', 'area', 'slice', 'slices', 'coords',\n",
    "            'initial', 'final', 'tone',\n",
    "            'initials_distance', 'finals_distance', 'tones_distance', 'overall_distance'\n",
    "        ]\n",
    "        if features is None:\n",
    "            features_to_load = all_features\n",
    "        else:\n",
    "            features_to_load = [f for f in features if f in all_features]\n",
    "            if len(features_to_load) != len(features):\n",
    "                print(f\"Warning: Some requested features for {name} are not available.\")\n",
    "\n",
    "        # 加载 pkl 文件中的数据\n",
    "        pkl_features = ['word_name', 'area', 'slice', 'slices', 'coords', 'initial', 'final', 'tone']\n",
    "        if any(f in features_to_load for f in pkl_features):\n",
    "            try:\n",
    "                with open(data4_dir, 'rb') as f:\n",
    "                    data_dict = pickle.load(f)\n",
    "                if 'initial' in features_to_load:\n",
    "                     loaded_data['initial'] = data_dict.get('initial')\n",
    "                if 'final' in features_to_load:\n",
    "                     loaded_data['final'] = data_dict.get('final')\n",
    "                if 'tone' in features_to_load:\n",
    "                     loaded_data['tone'] = data_dict.get('tone')\n",
    "                if 'word_name' in features_to_load:\n",
    "                    loaded_data['word_name'] = data_dict.get('word_name')\n",
    "                if 'area' in features_to_load:\n",
    "                    loaded_data['area'] = data_dict.get('area')\n",
    "                if 'slice' in features_to_load:\n",
    "                    loaded_data['slice'] = data_dict.get('slice')\n",
    "                if 'slices' in features_to_load:\n",
    "                    loaded_data['slices'] = data_dict.get('slices')\n",
    "                if 'coords' in features_to_load:\n",
    "                    loaded_data['coords'] = data_dict.get('coords')\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: {data4_dir} not found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {data4_dir}: {e}\")\n",
    "\n",
    "\n",
    "        # 加载 npz 文件中的数据\n",
    "        npz_features = ['initials_distance', 'finals_distance', 'tones_distance', 'overall_distance']\n",
    "        if any(f in features_to_load for f in npz_features):\n",
    "            try:\n",
    "                loaded_npz = np.load(data4_dir_matrix)\n",
    "                if 'initials_distance' in features_to_load:\n",
    "                    loaded_data['initials_distance'] = loaded_npz.get('initials')\n",
    "                if 'finals_distance' in features_to_load:\n",
    "                    loaded_data['finals_distance'] = loaded_npz.get('finals')\n",
    "                if 'tones_distance' in features_to_load:\n",
    "                    loaded_data['tones_distance'] = loaded_npz.get('tones')\n",
    "                if 'overall_distance' in features_to_load:\n",
    "                     loaded_data['overall_distance'] = loaded_npz.get('overall')\n",
    "                loaded_npz.close() # Close the npz file\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: {data4_dir_matrix} not found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {data4_dir_matrix}: {e}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Dataset '{name}' not found.\")\n",
    "\n",
    "    return loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os # 导入 os 库用于路径拼接\n",
    "\n",
    "# --- 数据文件路径定义 (请根据你的实际文件位置修改这些路径) ---\n",
    "# 假设你的数据文件存放在项目根目录下的 data/Data4 文件夹内\n",
    "# 你可能需要根据实际情况调整这些路径\n",
    "BASE_DATA3_DIR, BASE_DATA4_DIR, BASE_DATA2_DIR, BASE_DATA1_DIR = 'Data3', 'Data4', 'Data2', 'Data1' # 数据文件所在的基准目录\n",
    "\n",
    "# Data4 的原始转写和元数据 pkl 文件\n",
    "data4_raw_data_path = os.path.join(BASE_DATA4_DIR, 'transcription_areas.pkl') \n",
    "data4_distance_matrix_path = os.path.join(BASE_DATA4_DIR, 'distance_matrices.npz')\n",
    "data4_processed_info_path = os.path.join(BASE_DATA4_DIR, 'processed_info.pkl')\n",
    "# -------------------------------------------------------------\n",
    "data3_distance_matrix_path = os.path.join(BASE_DATA3_DIR, 'distance_matrices.npz')\n",
    "data3_processed_info_path = os.path.join(BASE_DATA3_DIR, 'info.npz')\n",
    "# -------------------------------------------------------------\n",
    "data1_processed_info_path = os.path.join(BASE_DATA1_DIR, 'data.pkl')\n",
    "# -------------------------------------------------------------\n",
    "data2_mfcc_dialect_mean_path = os.path.join(BASE_DATA2_DIR, 'dialect_mean_features.npz') \n",
    "data2_mfcc_dialect_slice_path = os.path.join(BASE_DATA2_DIR, 'dialect_slice_mean_features.npz') \n",
    "data2_mfcc_dialect_gmm_ivector_path = os.path.join(BASE_DATA2_DIR, 'mfcc_gmm_ivectordialect.npz') \n",
    "\n",
    "\n",
    "def load_feats(name, type=None, features=None):\n",
    "    \"\"\"\n",
    "    加载指定数据集的指定类型或指定特征的数据。\n",
    "\n",
    "    Args:\n",
    "        name (str): 数据集名称 (e.g., 'Data4')\n",
    "        type (str, optional): 需要加载的数据类型 (e.g., 'raw', 'distance_matrices').\n",
    "                              如果指定 type，函数会加载该类型下的预定义特征。\n",
    "                              如果 type 为 None，则必须通过 features 参数指定要加载的特征。\n",
    "        features (list, optional): 需要加载的特征列表.\n",
    "                                     如果 type 已指定，features 可用于过滤该类型下的特征。\n",
    "                                     如果 type 为 None，则加载此列表中指定的特征。\n",
    "                                     Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含请求特征的字典，键为特征名，值为对应的数据。\n",
    "              如果加载失败或未找到数据集/类型，返回空字典或 None。\n",
    "    \"\"\"\n",
    "    loaded_data = {}\n",
    "\n",
    "    # --- 定义不同数据集和类型下的特征列表和文件路径 ---\n",
    "    # 这个字典定义了每个数据集名称下，不同类型对应哪些预定义特征以及从哪个文件加载\n",
    "    DATASET_CONFIG = {\n",
    "        'Data4': {\n",
    "            'raw': {\n",
    "                'file': data4_raw_data_path,\n",
    "                'pkl_keys': ['word_name', 'area', 'slice', 'slices', 'coords', 'initial', 'final', 'tone'],\n",
    "                'loader': 'pickle' # 指定加载方式\n",
    "            },\n",
    "            'distance_matrices': {\n",
    "                'file': data4_distance_matrix_path,\n",
    "                'npz_keys': ['initials', 'finals', 'tones', 'overall'], # npz 文件中的键名\n",
    "                'output_keys': ['initials_distance', 'finals_distance', 'tones_distance', 'overall_distance'], # 输出字典中的键名\n",
    "                'loader': 'numpy_npz' # 指定加载方式\n",
    "            },\n",
    "            'info': {\n",
    "                'file': data4_processed_info_path,\n",
    "                # 处理后信息文件的键名和输出键名一致\n",
    "                'pkl_keys': ['areas', 'slice', 'slices', 'coords', 'word_names'], # 注意这里的键名与保存时字典的键名对应\n",
    "                'loader': 'pickle'}\n",
    "            # 可以继续添加其他 type...\n",
    "            # 'another_type': {...}\n",
    "        },\n",
    "        'Data3': {\n",
    "            'distance_matrices': {\n",
    "                'file': data3_distance_matrix_path,\n",
    "                'npz_keys': ['lexicon', 'phonology', 'syntax', 'overall'], # npz 文件中的键名\n",
    "                'output_keys': ['lexicon_distance', 'phonology_distance', 'syntax_distance', 'overall_distance'], # 输出字典中的键名\n",
    "                'loader': 'numpy_npz' # 指定加载方式\n",
    "            },\n",
    "            'info': {\n",
    "                'file': data3_processed_info_path,\n",
    "                # 处理后信息文件的键名和输出键名一致\n",
    "                'npz_keys': ['coords'], # 注意这里的键名与保存时字典的键名对应\n",
    "                'output_keys': ['coords'],\n",
    "                'loader': 'numpy_npz'}\n",
    "            # 可以继续添加其他 type...\n",
    "            # 'another_type': {...}\n",
    "        },\n",
    "        'Data1':{\n",
    "            'info': {\n",
    "                'file': data1_processed_info_path,\n",
    "                # 处理后信息文件的键名和输出键名一致\n",
    "                'pkl_keys': ['word', 'initial', 'final_1', 'final_2', 'final_3', 'tone'], # 注意这里的键名与保存时字典的键名对应\n",
    "                'loader': 'pickle'}\n",
    "        },\n",
    "        'Data2':{\n",
    "            'mfcc_dialect_mean': {\n",
    "                'file': data2_mfcc_dialect_mean_path,\n",
    "                'npz_keys': ['features', 'dialect_names'], # npz 文件中的键名\n",
    "                'output_keys': ['features', 'names'], # 输出字典中的键名\n",
    "                'loader': 'numpy_npz' # 指定加载方式\n",
    "            },\n",
    "            'mfcc_slice_mean': {\n",
    "                'file': data2_mfcc_dialect_slice_path,\n",
    "                'npz_keys': ['features', 'slice_names'], # npz 文件中的键名\n",
    "                'output_keys': ['features', 'names'], # 输出字典中的键名\n",
    "                'loader': 'numpy_npz' # 指定加载方式\n",
    "            },  \n",
    "            'mfcc_dialect_gmm_ivector': {\n",
    "                'file': data2_mfcc_dialect_gmm_ivector_path,\n",
    "                'npz_keys': ['features', 'dialect_names'], # npz 文件中的键名\n",
    "                'output_keys': ['features', 'names'], # 输出字典中的键名\n",
    "                'loader': 'numpy_npz' # 指定加载方式\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # --- 检查数据集名称是否存在 ---\n",
    "    if name not in DATASET_CONFIG:\n",
    "        print(f\"错误: 数据集 '{name}' 的配置不存在。\")\n",
    "        return {} # 返回空字典表示失败\n",
    "\n",
    "    dataset_config = DATASET_CONFIG[name]\n",
    "\n",
    "    # --- 根据 type 或 features 确定要加载的特征和文件 ---\n",
    "    features_to_load_final = [] # 最终确定要加载的特征列表\n",
    "    file_to_load = None\n",
    "    loader_type = None\n",
    "    source_keys = {} # 记录源文件中的键名到目标输出键名的映射\n",
    "\n",
    "    if type:\n",
    "        if type not in dataset_config:\n",
    "            print(f\"错误: 数据集 '{name}' 不支持类型 '{type}'。\")\n",
    "            return {}\n",
    "\n",
    "        type_config = dataset_config[type]\n",
    "        file_to_load = type_config.get('file')\n",
    "        loader_type = type_config.get('loader')\n",
    "\n",
    "        if loader_type == 'pickle':\n",
    "            all_type_features = type_config.get('pkl_keys', [])\n",
    "            # pickle 加载是直接从字典取，源键和输出键一致\n",
    "            source_keys = {k: k for k in all_type_features}\n",
    "        elif loader_type == 'numpy_npz':\n",
    "            all_type_features = type_config.get('output_keys', [])\n",
    "            # npz 加载需要处理源键到输出键的映射\n",
    "            npz_keys = type_config.get('npz_keys', [])\n",
    "            output_keys = type_config.get('output_keys', [])\n",
    "            if len(npz_keys) == len(output_keys):\n",
    "                 source_keys = dict(zip(output_keys, npz_keys)) # 存储 输出键 -> 源键 映射\n",
    "            else:\n",
    "                 print(f\"配置错误: 数据集 '{name}', 类型 '{type}' 的 npz_keys 和 output_keys 数量不匹配。\")\n",
    "                 return {}\n",
    "        else:\n",
    "             print(f\"配置错误: 数据集 '{name}', 类型 '{type}' 指定了未知的 loader '{loader_type}'。\")\n",
    "             return {}\n",
    "\n",
    "\n",
    "        if features is None:\n",
    "            # 如果没有指定 features，则加载该 type 下的所有预定义特征\n",
    "            features_to_load_final = all_type_features\n",
    "        else:\n",
    "            # 如果指定了 features，则加载该 type 下 features 中包含的特征\n",
    "            features_to_load_final = [f for f in features if f in all_type_features]\n",
    "            if len(features_to_load_final) != len(features):\n",
    "                # 检查用户请求的 features 中是否有不属于该 type 的\n",
    "                not_available = [f for f in features if f not in all_type_features]\n",
    "                print(f\"警告: 请求的特征 {not_available} 不属于数据集 '{name}' 的类型 '{type}'，将被忽略。\")\n",
    "\n",
    "    elif features is not None:\n",
    "         # 如果 type 为 None 但指定了 features (旧的使用方式，可以保留兼容性或弃用)\n",
    "         # 为了新设计清晰，建议要求必须指定 type\n",
    "         print(\"错误: 未指定数据加载类型 (type)，请指定如 type='raw'。\")\n",
    "         return {}\n",
    "         # 以下是保留旧 features 用法的代码，如果需要兼容可以启用：\n",
    "         # print(\"警告: 未指定数据类型 (type)，尝试按特征列表加载 (旧模式)。\")\n",
    "         # # 需要遍历所有 type 才能找到哪些特征在哪里，比较复杂，不推荐。\n",
    "         # # 更好的方式是：要求用户必须指定 type。\n",
    "         # pass # 在新设计中不推荐无 type 加载\n",
    "\n",
    "    else:\n",
    "        # type 和 features 都为 None\n",
    "        print(\"错误: 既未指定数据加载类型 (type)，也未指定要加载的特征列表 (features)。\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "    # --- 执行数据加载 ---\n",
    "    if not file_to_load:\n",
    "         print(\"内部错误: 未能确定要加载的文件路径。\")\n",
    "         return {}\n",
    "\n",
    "    if not features_to_load_final:\n",
    "        print(f\"未找到需要加载的特征列表，请检查 type 或 features 参数。\")\n",
    "        return {}\n",
    "\n",
    "    print(f\"正在从文件 '{file_to_load}' 加载数据...\")\n",
    "    print(f\"计划加载的特征: {features_to_load_final}\")\n",
    "\n",
    "    try:\n",
    "        if loader_type == 'pickle':\n",
    "            with open(file_to_load, 'rb') as f:\n",
    "                data_dict = pickle.load(f)\n",
    "\n",
    "            for feature_name in features_to_load_final:\n",
    "                # 从加载的字典中按特征名获取数据\n",
    "                # 使用 .get() 避免 KeyError 如果文件中的确缺少该特征\n",
    "                if feature_name in data_dict:\n",
    "                     loaded_data[feature_name] = data_dict[feature_name]\n",
    "                else:\n",
    "                     print(f\"警告: 在文件 '{file_to_load}' 中未找到特征 '{feature_name}'。\")\n",
    "\n",
    "        elif loader_type == 'numpy_npz':\n",
    "            loaded_npz = np.load(file_to_load)\n",
    "            for output_key in features_to_load_final:\n",
    "                 source_key = source_keys.get(output_key) # 获取 npz 文件中的对应键\n",
    "                 if source_key and source_key in loaded_npz:\n",
    "                     loaded_data[output_key] = loaded_npz[source_key]\n",
    "                 else:\n",
    "                     print(f\"警告: 在文件 '{file_to_load}' 中未找到特征 '{output_key}' (查找键 '{source_key}')。\")\n",
    "            loaded_npz.close() # 关闭 npz 文件句柄\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 数据文件 '{file_to_load}' 未找到。请检查路径设置。\")\n",
    "        return {} # 返回空字典表示失败\n",
    "    except Exception as e:\n",
    "        print(f\"错误加载文件 '{file_to_load}': {e}\")\n",
    "        return {} # 返回空字典表示失败\n",
    "\n",
    "    print(f\"成功加载 {len(loaded_data)} 个特征。\")\n",
    "    return loaded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从文件 'Data4/transcription_areas.pkl' 加载数据...\n",
      "计划加载的特征: ['word_name', 'area', 'slice', 'slices', 'coords', 'initial', 'final', 'tone']\n",
      "成功加载 8 个特征。\n"
     ]
    }
   ],
   "source": [
    "dict_ = load_feats(name='Data4', type='raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = load_feats(name='Data4', type='raw')\n",
    "# ['initial', 'final', 'tone', 'word_name', 'area', 'slice', 'slices', 'coords']\n",
    "initials, finals, tones, word_names, areas, slice, slices, coords = dict['initial'], dict['final'], dict['tone'], dict['word_name'], dict['area'], dict['slice'], dict['slices'], dict['coords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Calculate and Save Distance Matrix\n",
    "We first calculate the ratio of missing values of different dialects and features, any only select those with non-missing value above 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Ratio of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ratio_missing_transcription(numpy_array, missing_value='MISSING', threshold_percentage=30):\n",
    "    \"\"\"\n",
    "    分析 NumPy 数组中指定缺失值的比例，找出超过阈值的行和列，\n",
    "    并返回缺失比例最高的各自 Top 10。输出结果使用标准 Python 数字类型。\n",
    "\n",
    "    Args:\n",
    "        numpy_array (np.ndarray): 输入的 NumPy 数组，应为二维。\n",
    "        missing_value (str): 表示缺失值的字符串或值，默认为 'MISSING'。\n",
    "        threshold_percentage (int or float): 缺失值比例阈值 (0-100)，\n",
    "                                            超过此比例的行/列会被单独列出。默认为 30。\n",
    "\n",
    "    Returns:\n",
    "        dict: 包含分析结果的字典，键值如下：\n",
    "            'rows_over_threshold': 缺失比例超过阈值的行索引列表 (Python int)。\n",
    "            'cols_over_threshold': 缺失比例超过阈值的列索引列表 (Python int)。\n",
    "            'top10_rows': 缺失比例最高的 Top 10 行 (索引, 比例) 列表。\n",
    "                           格式为 [(行索引: Python int, 缺失百分比: Python float), ...]。\n",
    "            'top10_cols': 缺失比例最高的 Top 10 列 (索引, 比例) 列表。\n",
    "                           格式为 [(列索引: Python int, 缺失百分比: Python float), ...]。\n",
    "        None: 如果输入不是二维 NumPy 数组，则返回 None 并打印错误信息。\n",
    "    \"\"\"\n",
    "    if not isinstance(numpy_array, np.ndarray) or numpy_array.ndim != 2:\n",
    "        print(\"错误：输入必须是一个二维 NumPy 数组。\")\n",
    "        return None\n",
    "\n",
    "    n_rows, n_cols = numpy_array.shape\n",
    "    print(f\"正在分析一个 {n_rows} 行, {n_cols} 列的数组...\")\n",
    "    print(f\"缺失值标记为: '{missing_value}'\")\n",
    "    print(f\"缺失比例阈值为: {threshold_percentage}%\")\n",
    "\n",
    "    # 创建一个布尔掩码，标记出所有缺失值的位置\n",
    "    missing_mask = (numpy_array == missing_value)\n",
    "\n",
    "    # --- 计算每行的缺失比例 ---\n",
    "    row_missing_counts = np.sum(missing_mask, axis=1)\n",
    "    row_missing_percentages = (row_missing_counts / n_cols) * 100\n",
    "\n",
    "    # --- 计算每列的缺失比例 ---\n",
    "    col_missing_counts = np.sum(missing_mask, axis=0)\n",
    "    col_missing_percentages = (col_missing_counts / n_rows) * 100\n",
    "\n",
    "    print(\"缺失比例计算完成。\")\n",
    "\n",
    "    # --- 找出比例超过阈值的行和列 ---\n",
    "    # 转换为标准 Python int 列表\n",
    "    rows_over_threshold_indices = [int(i) for i in np.where(row_missing_percentages > threshold_percentage)[0]]\n",
    "    cols_over_threshold_indices = [int(i) for i in np.where(col_missing_percentages > threshold_percentage)[0]]\n",
    "\n",
    "    print(f\"发现 {len(rows_over_threshold_indices)} 行的缺失比例超过 {threshold_percentage}%。\")\n",
    "    print(f\"发现 {len(cols_over_threshold_indices)} 列的缺失比例超过 {threshold_percentage}%。\")\n",
    "\n",
    "    # --- 找出缺失比例最高的 Top 10 行 ---\n",
    "    top10_row_indices = np.argsort(-row_missing_percentages)[:10]\n",
    "    top10_row_percentages = row_missing_percentages[top10_row_indices]\n",
    "    # 转换为标准 Python int 和 float 元组列表\n",
    "    top10_rows_result = [(int(idx), float(round(pct, 2))) for idx, pct in zip(top10_row_indices, top10_row_percentages)]\n",
    "\n",
    "    # --- 找出缺失比例最高的 Top 10 列 ---\n",
    "    top10_col_indices = np.argsort(-col_missing_percentages)[:10]\n",
    "    top10_col_percentages = col_missing_percentages[top10_col_indices]\n",
    "    # 转换为标准 Python int 和 float 元组列表\n",
    "    top10_cols_result = [(int(idx), float(round(pct, 2))) for idx, pct in zip(top10_col_indices, top10_col_percentages)]\n",
    "\n",
    "    print(\"Top 10 缺失比例行/列计算完成。\")\n",
    "\n",
    "    # --- 构建结果字典 ---\n",
    "    results = {\n",
    "        'rows_over_threshold': rows_over_threshold_indices,\n",
    "        'cols_over_threshold': cols_over_threshold_indices,\n",
    "        'top10_rows': top10_rows_result,\n",
    "        'top10_cols': top10_cols_result,\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析一个 1289 行, 999 列的数组...\n",
      "缺失值标记为: 'MISSING'\n",
      "缺失比例阈值为: 20%\n",
      "缺失比例计算完成。\n",
      "发现 6 行的缺失比例超过 20%。\n",
      "发现 2 列的缺失比例超过 20%。\n",
      "Top 10 缺失比例行/列计算完成。\n"
     ]
    }
   ],
   "source": [
    "results_initials = ratio_missing_transcription(initials, missing_value='MISSING', threshold_percentage=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析一个 1289 行, 999 列的数组...\n",
      "缺失值标记为: 'MISSING'\n",
      "缺失比例阈值为: 20%\n",
      "缺失比例计算完成。\n",
      "发现 186 行的缺失比例超过 20%。\n",
      "发现 84 列的缺失比例超过 20%。\n",
      "Top 10 缺失比例行/列计算完成。\n"
     ]
    }
   ],
   "source": [
    "results_finals = ratio_missing_transcription(finals, missing_value='MISSING', threshold_percentage=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在分析一个 1289 行, 999 列的数组...\n",
      "缺失值标记为: 'MISSING'\n",
      "缺失比例阈值为: 20%\n",
      "缺失比例计算完成。\n",
      "发现 23 行的缺失比例超过 20%。\n",
      "发现 2 列的缺失比例超过 20%。\n",
      "Top 10 缺失比例行/列计算完成。\n"
     ]
    }
   ],
   "source": [
    "results_tones = ratio_missing_transcription(tones, missing_value='MISSING', threshold_percentage=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205 [7, 520, 524, 14, 1039, 17, 533, 535, 541, 31, 550, 551, 40, 41, 553, 555, 556, 559, 561, 562, 563, 564, 565, 568, 574, 575, 1087, 580, 583, 585, 586, 587, 76, 588, 81, 1105, 83, 595, 596, 87, 599, 604, 1117, 94, 606, 1124, 101, 104, 108, 111, 112, 113, 114, 115, 1138, 118, 1144, 121, 1147, 125, 131, 132, 644, 134, 1155, 138, 141, 144, 145, 146, 656, 148, 149, 150, 151, 153, 1178, 669, 158, 159, 1185, 673, 165, 677, 168, 1193, 170, 171, 172, 174, 1199, 176, 1200, 178, 692, 1205, 1211, 187, 189, 1213, 192, 705, 196, 197, 710, 1221, 1224, 1226, 204, 1230, 719, 1231, 724, 734, 1248, 1250, 1251, 1259, 1263, 1264, 1273, 1274, 254, 1282, 259, 1284, 1286, 1288, 277, 286, 288, 801, 296, 331, 848, 850, 853, 345, 347, 859, 864, 865, 873, 878, 372, 886, 890, 378, 380, 386, 387, 904, 397, 398, 911, 913, 405, 408, 409, 412, 928, 932, 422, 424, 425, 427, 428, 431, 432, 434, 439, 441, 958, 961, 450, 963, 964, 965, 969, 459, 460, 971, 974, 972, 973, 976, 982, 983, 473, 1016, 988, 476, 477, 479, 480, 992, 996, 1003, 494, 1008, 1012, 1013, 500, 504, 511]\n",
      "84 [26, 562, 565, 566, 567, 571, 572, 576, 577, 578, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 600, 601, 607, 608, 609, 610, 611, 615, 616, 618, 619, 620, 669, 670, 672, 673, 677, 683, 684, 685, 686, 689, 696, 697, 698, 699, 700, 203, 220, 221, 222, 749, 750, 239, 751, 752, 753, 754, 755, 756, 770, 828, 365, 366, 368, 369, 371, 907, 912, 401, 970, 971, 972, 477, 994, 995, 996, 997, 998]\n"
     ]
    }
   ],
   "source": [
    "# first operate dialects \n",
    "all_row_indices = results_initials['rows_over_threshold'] + results_finals['rows_over_threshold'] + results_tones['rows_over_threshold']\n",
    "unique_row_indices_set = set(all_row_indices)\n",
    "unique_row_indices_list = list(unique_row_indices_set)\n",
    "print(len(unique_row_indices_list), unique_row_indices_list)\n",
    "\n",
    "all_col_indices = results_initials['cols_over_threshold'] + results_finals['cols_over_threshold'] + results_tones['cols_over_threshold']\n",
    "unique_col_indices_set = set(all_col_indices)\n",
    "unique_col_indices_list = list(unique_col_indices_set)\n",
    "print(len(unique_col_indices_list), unique_col_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def remove_rows_and_cols(numpy_array, rows_to_delete, cols_to_delete):\n",
    "    \"\"\"\n",
    "    从一个二维 NumPy 数组中删除指定的行和列。\n",
    "\n",
    "    Args:\n",
    "        numpy_array (np.ndarray): 输入的二维 NumPy 数组。\n",
    "        rows_to_delete (list or array_like): 要删除的行的索引列表或数组。\n",
    "        cols_to_delete (list or array_like): 要删除的列的索引列表或数组。\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 删除指定行和列后的新的 NumPy 数组。\n",
    "        None: 如果输入不是二维 NumPy 数组，则返回 None 并打印错误信息。\n",
    "    \"\"\"\n",
    "    if not isinstance(numpy_array, np.ndarray) or numpy_array.ndim != 2:\n",
    "        print(\"错误：输入必须是一个二维 NumPy 数组。\")\n",
    "        return None\n",
    "\n",
    "    print(f\"原始数组维度: {numpy_array.shape}\")\n",
    "    print(f\"将删除 {len(rows_to_delete)} 行和 {len(cols_to_delete)} 列...\")\n",
    "\n",
    "    # 使用 np.delete 删除行\n",
    "    # axis=0 表示删除行\n",
    "    # 返回一个新的数组，原始数组不变\n",
    "    array_after_rows_deleted = np.delete(numpy_array, rows_to_delete, axis=0)\n",
    "\n",
    "    # 使用 np.delete 删除列\n",
    "    # 注意：这里是在删除行后的新数组上操作\n",
    "    # axis=1 表示删除列\n",
    "    array_after_cols_deleted = np.delete(array_after_rows_deleted, cols_to_delete, axis=1)\n",
    "\n",
    "    print(f\"删除后的数组维度: {array_after_cols_deleted.shape}\")\n",
    "\n",
    "    return array_after_cols_deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数组维度: (1289, 999)\n",
      "将删除 205 行和 84 列...\n",
      "删除后的数组维度: (1084, 915)\n",
      "原始数组维度: (1289, 999)\n",
      "将删除 205 行和 84 列...\n",
      "删除后的数组维度: (1084, 915)\n",
      "原始数组维度: (1289, 999)\n",
      "将删除 205 行和 84 列...\n",
      "删除后的数组维度: (1084, 915)\n"
     ]
    }
   ],
   "source": [
    "processed_initials = remove_rows_and_cols(initials, unique_row_indices_list, unique_col_indices_list)\n",
    "processed_finals = remove_rows_and_cols(finals, unique_row_indices_list, unique_col_indices_list)\n",
    "processed_tones = remove_rows_and_cols(tones, unique_row_indices_list, unique_col_indices_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Distance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Optional: Import tqdm for a progress bar, useful for large datasets\n",
    "# from tqdm.auto import tqdm # pip install tqdm\n",
    "\n",
    "def cal_distance(features, missing_value='MISSING'):\n",
    "    \"\"\"\n",
    "    Calculate the distance matrix between dialects based on feature differences.\n",
    "\n",
    "    The distance d(i, j) is the number of features where dialects i and j differ,\n",
    "    divided by the number of features where *neither* dialect i nor j has a\n",
    "    missing value.\n",
    "\n",
    "    Args:\n",
    "        features (np.ndarray): 2D array [n_dialects, n_features], dtype=object.\n",
    "                               Contains feature values (usually strings).\n",
    "        missing_value (str): Indicator of missing values (e.g., 'MISSING', 'Ǿ').\n",
    "                               Features with this value are ignored in pairwise comparisons.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Distance matrix [n_dialects, n_dialects], dtype=float.\n",
    "                    dist_matrix[i, j] is the calculated distance.\n",
    "                    Returns np.nan if a pair of dialects has no comparable features\n",
    "                    (i.e., for every feature, at least one has a missing value).\n",
    "    \"\"\"\n",
    "    if not isinstance(features, np.ndarray) or features.ndim != 2:\n",
    "        raise ValueError(\"Input 'features' must be a 2D NumPy array.\")\n",
    "\n",
    "    n_dialects, n_features = features.shape\n",
    "    print(f\"Calculating distance matrix for {n_dialects} dialects and {n_features} features...\")\n",
    "    print(f\"Using '{missing_value}' as the missing value indicator.\")\n",
    "\n",
    "    # Initialize distance matrix - using np.nan allows easy identification\n",
    "    # of pairs with no comparable features. Diagonal will be set to 0.\n",
    "    dist_matrix = np.full((n_dialects, n_dialects), np.nan, dtype=float)\n",
    "\n",
    "    # Pre-calculate a boolean mask indicating where features are *not* missing\n",
    "    # This avoids repeated comparisons with missing_value inside the loops\n",
    "    is_valid = (features != missing_value)\n",
    "    print(\"Pre-calculated validity mask.\")\n",
    "\n",
    "    # --- Iterate through all unique pairs of dialects (i, j) ---\n",
    "    # Using tqdm here provides a nice progress bar: range(n_dialects) -> tqdm(range(n_dialects))\n",
    "    # for i in tqdm(range(n_dialects), desc=\"Calculating distances\"):\n",
    "    for i in range(n_dialects):\n",
    "        # Optional: Print progress every N dialects\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Processed {i+1}/{n_dialects} dialects...\")\n",
    "\n",
    "        # Distance from a dialect to itself is 0\n",
    "        dist_matrix[i, i] = 0.0\n",
    "\n",
    "        # Get data and validity mask for dialect i once\n",
    "        features_i = features[i]\n",
    "        is_valid_i = is_valid[i]\n",
    "\n",
    "        # Compare dialect i with dialects j where j > i\n",
    "        for j in range(i + 1, n_dialects):\n",
    "            features_j = features[j]\n",
    "            is_valid_j = is_valid[j]\n",
    "\n",
    "            # 1. Find features where *both* dialects have valid data\n",
    "            #    (element-wise AND)\n",
    "            valid_comparison_mask = is_valid_i & is_valid_j\n",
    "\n",
    "            # 2. Count how many features are valid for this pair\n",
    "            num_valid_features = np.sum(valid_comparison_mask)\n",
    "\n",
    "            # 3. Handle case where there are no features to compare\n",
    "            if num_valid_features == 0:\n",
    "                # Distance is undefined, leave as np.nan\n",
    "                # dist_matrix[i, j] = np.nan # Already initialized to NaN\n",
    "                dist_matrix[j, i] = np.nan # Ensure symmetry for NaN too\n",
    "                continue # Move to the next pair (j)\n",
    "\n",
    "            # 4. Compare feature values *only* where both are valid\n",
    "            #    First, find all differing features between the full rows\n",
    "            feature_differs = (features_i != features_j)\n",
    "            #    Then, select differences only where the comparison was valid\n",
    "            valid_differences_mask = feature_differs & valid_comparison_mask\n",
    "\n",
    "            # 5. Count the number of valid differences\n",
    "            num_differences = np.sum(valid_differences_mask)\n",
    "\n",
    "            # 6. Calculate the distance\n",
    "            distance = num_differences / num_valid_features\n",
    "\n",
    "            # 7. Store the distance (and maintain symmetry)\n",
    "            dist_matrix[i, j] = distance\n",
    "            dist_matrix[j, i] = distance\n",
    "\n",
    "    print(\"Distance matrix calculation finished.\")\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials_distance = cal_distance(processed_initials)\n",
    "finals_distance = cal_distance(processed_finals)\n",
    "tones_distance = cal_distance(processed_tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功将距离矩阵保存到: Data4/distance_matrices.npz\n"
     ]
    }
   ],
   "source": [
    "overall_distance = (initials_distance + finals_distance + tones_distance) / 3\n",
    "output_filename = 'Data4/distance_matrices.npz'\n",
    "np.savez_compressed(\n",
    "    output_filename,\n",
    "    initials=initials_distance,  # 在 .npz 文件中，这个矩阵被称为 'initials'\n",
    "    finals=finals_distance,    # 这个被称为 'finals'\n",
    "    tones=tones_distance,       # 这个被称为 'tones'\n",
    "    overall=overall_distance  # 如果需要，可以添加整体距离矩阵\n",
    ")\n",
    "print(f\"成功将距离矩阵保存到: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "尝试加载文件: Data4/distance_matrices.npz\n",
      "文件中包含的数组名称: ['initials', 'finals', 'tones', 'overall']\n",
      "加载的 'initials' 矩阵形状: (1084, 1084)\n",
      "加载的 'finals' 矩阵形状: (1084, 1084)\n",
      "加载的 'tones' 矩阵形状: (1084, 1084)\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'Data4/distance_matrices.npz'\n",
    "print(f\"\\n尝试加载文件: {output_filename}\")\n",
    "loaded_data = np.load(output_filename)\n",
    "\n",
    "# 检查文件中有哪些数组\n",
    "print(f\"文件中包含的数组名称: {list(loaded_data.keys())}\")\n",
    "\n",
    "# 加载单个数组\n",
    "loaded_initials = loaded_data['initials']\n",
    "loaded_finals = loaded_data['finals']\n",
    "loaded_tones = loaded_data['tones']\n",
    "overall_distance = loaded_data['overall']\n",
    "\n",
    "print(f\"加载的 'initials' 矩阵形状: {loaded_initials.shape}\")\n",
    "print(f\"加载的 'finals' 矩阵形状: {loaded_finals.shape}\")\n",
    "print(f\"加载的 'tones' 矩阵形状: {loaded_tones.shape}\")\n",
    "\n",
    "# 不要忘记关闭文件（虽然对于 np.load 通常不是严格必需的，但好习惯）\n",
    "loaded_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "def get_missing_percentage(numpy_matrix: np.ndarray, missing_value: typing.Any = 'MISSING') -> float:\n",
    "    \"\"\"\n",
    "    计算 NumPy 数组中指定缺失值（默认为 'MISSING'）的元素比例。\n",
    "\n",
    "    Args:\n",
    "        numpy_matrix (np.ndarray): 输入的 NumPy 数组（可以是任意维度）。\n",
    "        missing_value (Any): 用来表示缺失值的值，默认为 'MISSING' 字符串。\n",
    "\n",
    "    Returns:\n",
    "        float: 元素中缺失值的百分比（0.0 到 100.0 之间）。\n",
    "               如果输入数组为空，返回 0.0。\n",
    "               如果输入不是 NumPy 数组，打印错误并返回 0.0。\n",
    "    \"\"\"\n",
    "    if not isinstance(numpy_matrix, np.ndarray):\n",
    "        print(\"错误: 输入必须是一个 NumPy 数组。\")\n",
    "        return 0.0\n",
    "\n",
    "    total_elements = numpy_matrix.size\n",
    "\n",
    "    # 检查数组是否为空，避免除以零\n",
    "    if total_elements == 0:\n",
    "        print(\"警告: 输入数组为空，缺失比例为 0%。\")\n",
    "        return 0.0\n",
    "\n",
    "    # 创建布尔掩码，True 表示元素等于 missing_value\n",
    "    missing_mask = (numpy_matrix == missing_value)\n",
    "\n",
    "    # 统计缺失值的数量 (True 会被当作 1 求和)\n",
    "    missing_count = np.sum(missing_mask)\n",
    "\n",
    "    # 计算并返回百分比\n",
    "    percentage = (missing_count / total_elements) * 100.0\n",
    "    print(f\"缺失值比例: {percentage:.2f}%\")\n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值比例: 1.01%\n",
      "缺失值比例: 5.98%\n",
      "缺失值比例: 1.22%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.2160990462363641)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_missing_percentage(processed_initials, missing_value='MISSING')\n",
    "get_missing_percentage(processed_finals, missing_value='MISSING') \n",
    "get_missing_percentage(processed_tones, missing_value='MISSING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Processing Other Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "def remove_elements_or_rows_by_indices(data: typing.Union[list, np.ndarray], indices_to_delete: typing.List[int]) -> list:\n",
    "    \"\"\"\n",
    "    从列表、一维 NumPy 数组或二维 NumPy 数组中删除指定索引位置的元素/行。\n",
    "\n",
    "    Args:\n",
    "        data (list or np.ndarray): 输入的数据，可以是 Python 列表、一维或二维 NumPy 数组。\n",
    "        indices_to_delete (list): 包含要删除元素的索引（位置）或行的索引的列表（整数）。\n",
    "\n",
    "    Returns:\n",
    "        list: 删除指定元素/行后的结果，统一返回 Python 列表。\n",
    "              对于原始输入是列表或一维 NumPy 数组，返回的是一个扁平的列表。\n",
    "              对于原始输入是二维 NumPy 数组，返回的是一个列表的列表。\n",
    "              如果指定的索引超出范围，超出范围的索引会被忽略。\n",
    "              如果输入数据类型或 NumPy 数组维度不支持，返回 None 并打印错误。\n",
    "    \"\"\"\n",
    "    if not isinstance(indices_to_delete, list):\n",
    "        print(\"错误: 第二个输入（indices_to_delete）必须是 list 类型。\")\n",
    "        return None\n",
    "\n",
    "    # 为了高效查找索引，转换为集合\n",
    "    indices_to_delete_set = set(indices_to_delete)\n",
    "    print(f\"计划删除 {len(indices_to_delete)} 个索引。\")\n",
    "\n",
    "    result_list = None # 初始化为 None，表示尚未成功处理\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        print(\"输入类型: Python 列表\")\n",
    "        print(f\"原始列表长度: {len(data)}\")\n",
    "        # 使用列表推导式创建新列表，只包含索引不在删除集合中的元素\n",
    "        result_list = [item for i, item in enumerate(data) if i not in indices_to_delete_set]\n",
    "        print(f\"删除后列表长度: {len(result_list)}\")\n",
    "\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        print(\"输入类型: NumPy 数组\")\n",
    "        \n",
    "        array_after_deletion = None\n",
    "\n",
    "        if data.ndim == 1:\n",
    "            print(f\"原始 NumPy 数组维度: {data.shape} (一维)\")\n",
    "            # 对于一维数组，np.delete(arr, obj, axis=0) 或 axis=None 都可以删除元素\n",
    "            array_after_deletion = np.delete(data, list(indices_to_delete_set), axis=0)\n",
    "            print(f\"删除后 NumPy 数组维度: {array_after_deletion.shape}\")\n",
    "            # 将一维 NumPy 数组转换为 Python 列表\n",
    "            result_list = array_after_deletion.tolist()\n",
    "\n",
    "        elif data.ndim == 2:\n",
    "            print(f\"原始 NumPy 数组维度: {data.shape} (二维)\")\n",
    "            # 使用 np.delete 按行删除 (axis=0)\n",
    "            array_after_deletion = np.delete(data, list(indices_to_delete_set), axis=0)\n",
    "            print(f\"删除后 NumPy 数组维度: {array_after_deletion.shape}\")\n",
    "            # 将 NumPy 二维数组转换为 Python 列表的列表\n",
    "            result_list = array_after_deletion.tolist()\n",
    "            \n",
    "        else:\n",
    "            print(f\"错误: 输入的 NumPy 数组维度为 {data.ndim}，当前函数只支持一维或二维数组。\")\n",
    "            return None # 返回 None 表示处理失败\n",
    "\n",
    "    else:\n",
    "        print(f\"错误: 不支持的数据类型 '{type(data)}'。输入必须是 list 或 np.ndarray。\")\n",
    "        return None # 返回 None 表示处理失败\n",
    "\n",
    "    return result_list # 返回最终的列表结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计划删除 84 个索引。\n",
      "输入类型: Python 列表\n",
      "原始列表长度: 999\n",
      "删除后列表长度: 915\n"
     ]
    }
   ],
   "source": [
    "removed_word_names = remove_elements_or_rows_by_indices(word_names, unique_col_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计划删除 205 个索引。\n",
      "输入类型: NumPy 数组\n",
      "原始 NumPy 数组维度: (1289,) (一维)\n",
      "删除后 NumPy 数组维度: (1084,)\n",
      "计划删除 205 个索引。\n",
      "输入类型: NumPy 数组\n",
      "原始 NumPy 数组维度: (1289,) (一维)\n",
      "删除后 NumPy 数组维度: (1084,)\n",
      "计划删除 205 个索引。\n",
      "输入类型: NumPy 数组\n",
      "原始 NumPy 数组维度: (1289,) (一维)\n",
      "删除后 NumPy 数组维度: (1084,)\n",
      "计划删除 205 个索引。\n",
      "输入类型: NumPy 数组\n",
      "原始 NumPy 数组维度: (1289, 2) (二维)\n",
      "删除后 NumPy 数组维度: (1084, 2)\n"
     ]
    }
   ],
   "source": [
    "removed_areas, removed_slice, removed_slices, removed_coords = remove_elements_or_rows_by_indices(areas, unique_row_indices_list), remove_elements_or_rows_by_indices(slice, unique_row_indices_list), remove_elements_or_rows_by_indices(slices, unique_row_indices_list), remove_elements_or_rows_by_indices(coords, unique_row_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功将处理后信息保存到 'Data4/processed_info.pkl'\n"
     ]
    }
   ],
   "source": [
    "removed_areas, removed_slice, removed_slices, removed_coords, removed_word_names\n",
    "\n",
    "output_path = 'Data4/processed_info.pkl'\n",
    "data_to_save = {\n",
    "        'areas': removed_areas,\n",
    "        'slice': removed_slice,\n",
    "        'slices': removed_slices,\n",
    "        'coords': removed_coords,\n",
    "        'word_names': removed_word_names\n",
    "    }\n",
    "\n",
    "# 确保目录存在\n",
    "output_dir = os.path.dirname(output_path)\n",
    "if output_dir: # 只有当路径包含目录时才创建\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(data_to_save, f)\n",
    "    print(f\"成功将处理后信息保存到 '{output_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"错误保存文件 '{output_path}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Data3/LCAD_distmatrix_0.csv', index_col=0).to_numpy()  \n",
    "data_lexicon = pd.read_csv('Data3/LCAD_distmatrix_lexicon.csv', index_col=0).to_numpy()  \n",
    "data_phonology = pd.read_csv('Data3/LCAD_distmatrix_phonology.csv', index_col=0).to_numpy()  \n",
    "data_syntax = pd.read_csv('Data3/LCAD_distmatrix_syntax.csv', index_col=0).to_numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功将距离矩阵保存到: Data3/info.npz\n"
     ]
    }
   ],
   "source": [
    "locations = pd.read_csv('Data3/cn_tax.csv', index_col=0)\n",
    "locs_df = locations[['long', 'lat']].to_numpy()\n",
    "\n",
    "output_filename = 'Data3/info.npz'\n",
    "np.savez_compressed(\n",
    "    output_filename,\n",
    "    coords=locs_df\n",
    ")\n",
    "print(f\"成功将距离矩阵保存到: {output_filename}\")\n",
    "\n",
    "#后续补充了方言区和方言小片再加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功将距离矩阵保存到: Data3/distance_matrices.npz\n"
     ]
    }
   ],
   "source": [
    "output_filename = 'Data3/distance_matrices.npz'\n",
    "np.savez_compressed(\n",
    "    output_filename,\n",
    "    lexicon=data_lexicon,  \n",
    "    phonology=data_phonology,    \n",
    "    syntax=data_syntax,       \n",
    "    overall=data  \n",
    ")\n",
    "print(f\"成功将距离矩阵保存到: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从文件 'Data3/distance_matrices.npz' 加载数据...\n",
      "计划加载的特征: ['lexicon_distance', 'phonology_distance', 'syntax_distance', 'overall_distance']\n",
      "成功加载 4 个特征。\n",
      "正在从文件 'Data3/info.npz' 加载数据...\n",
      "计划加载的特征: ['coords']\n",
      "成功加载 1 个特征。\n"
     ]
    }
   ],
   "source": [
    "raw_data_dict = load_feats(name='Data3', type='distance_matrices')\n",
    "info = load_feats(name='Data3', type='info')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从文件 'Data1/data.pkl' 加载数据...\n",
      "计划加载的特征: ['word', 'initial', 'final_1', 'final_2', 'final_3', 'tone']\n",
      "成功加载 6 个特征。\n"
     ]
    }
   ],
   "source": [
    "dict_ = load_feats(name='Data1', type='info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['多',\n",
       " '拖',\n",
       " '驼',\n",
       " '挪',\n",
       " '锣',\n",
       " '箩',\n",
       " '搓',\n",
       " '歌',\n",
       " '哥',\n",
       " '蛾',\n",
       " '鹅',\n",
       " '俄',\n",
       " '河',\n",
       " '何',\n",
       " '阿',\n",
       " '舵',\n",
       " '哪',\n",
       " '左',\n",
       " '可',\n",
       " '我',\n",
       " '那',\n",
       " '佐',\n",
       " '个',\n",
       " '饿',\n",
       " '贺',\n",
       " '茄',\n",
       " '波',\n",
       " '菠',\n",
       " '颇',\n",
       " '坡',\n",
       " '玻',\n",
       " '婆',\n",
       " '魔',\n",
       " '摩',\n",
       " '馍',\n",
       " '骡',\n",
       " '螺',\n",
       " '脶',\n",
       " '矬',\n",
       " '蓑',\n",
       " '梭',\n",
       " '嗦',\n",
       " '莎',\n",
       " '锅',\n",
       " '戈',\n",
       " '科',\n",
       " '窠',\n",
       " '棵',\n",
       " '讹',\n",
       " '禾',\n",
       " '倭',\n",
       " '踒',\n",
       " '窝',\n",
       " '跛',\n",
       " '朵',\n",
       " '妥',\n",
       " '椭',\n",
       " '惰',\n",
       " '垛',\n",
       " '裸',\n",
       " '瘰',\n",
       " '坐',\n",
       " '锁',\n",
       " '琐',\n",
       " '果',\n",
       " '裹',\n",
       " '馃',\n",
       " '颗',\n",
       " '火',\n",
       " '伙',\n",
       " '祸',\n",
       " '破',\n",
       " '剁',\n",
       " '唾',\n",
       " '糯',\n",
       " '摞',\n",
       " '锉',\n",
       " '座',\n",
       " '课',\n",
       " '卧',\n",
       " '货',\n",
       " '涴',\n",
       " '瘸',\n",
       " '膀',\n",
       " '巴',\n",
       " '芭',\n",
       " '疤',\n",
       " '爬',\n",
       " '琶',\n",
       " '杷',\n",
       " '钯',\n",
       " '麻',\n",
       " '痲',\n",
       " '蟆',\n",
       " '妈',\n",
       " '拿',\n",
       " '茶',\n",
       " '搽',\n",
       " '渣',\n",
       " '叉',\n",
       " '杈',\n",
       " '茬',\n",
       " '沙',\n",
       " '纱',\n",
       " '加',\n",
       " '痂',\n",
       " '嘉',\n",
       " '牙',\n",
       " '芽',\n",
       " '衙',\n",
       " '伢',\n",
       " '哈',\n",
       " '霞',\n",
       " '瑕',\n",
       " '遐',\n",
       " '鸦',\n",
       " '丫',\n",
       " '桠',\n",
       " '马',\n",
       " '码',\n",
       " '贾',\n",
       " '雅',\n",
       " '哑',\n",
       " '霸',\n",
       " '爸',\n",
       " '怕',\n",
       " '帕',\n",
       " '耙',\n",
       " '骂',\n",
       " '诈',\n",
       " '榨',\n",
       " '岔',\n",
       " '乍',\n",
       " '架',\n",
       " '驾',\n",
       " '嫁',\n",
       " '稼',\n",
       " '价',\n",
       " '揢',\n",
       " '砑',\n",
       " '暇',\n",
       " '亚',\n",
       " '些',\n",
       " '邪',\n",
       " '爹',\n",
       " '遮',\n",
       " '蛇',\n",
       " '奢',\n",
       " '赊',\n",
       " '佘',\n",
       " '耶',\n",
       " '爷',\n",
       " '姐',\n",
       " '且',\n",
       " '写',\n",
       " '者',\n",
       " '扯',\n",
       " '社',\n",
       " '惹',\n",
       " '也',\n",
       " '野',\n",
       " '借',\n",
       " '泻',\n",
       " '卸',\n",
       " '谢',\n",
       " '蔗',\n",
       " '麝',\n",
       " '赦',\n",
       " '騇',\n",
       " '夜',\n",
       " '髽',\n",
       " '瓜',\n",
       " '蜗',\n",
       " '夸',\n",
       " '花',\n",
       " '铧',\n",
       " '洼',\n",
       " '耍',\n",
       " '寡',\n",
       " '侉',\n",
       " '垮',\n",
       " '跨',\n",
       " '化',\n",
       " '桦',\n",
       " '蒲',\n",
       " '菩',\n",
       " '摹',\n",
       " '徒',\n",
       " '屠',\n",
       " '途',\n",
       " '涂',\n",
       " '图',\n",
       " '奴',\n",
       " '卢',\n",
       " '炉',\n",
       " '芦',\n",
       " '鸬',\n",
       " '租',\n",
       " '粗',\n",
       " '苏',\n",
       " '酥',\n",
       " '姑',\n",
       " '孤',\n",
       " '箍',\n",
       " '枯',\n",
       " '吴',\n",
       " '蜈',\n",
       " '吾',\n",
       " '梧',\n",
       " '呼',\n",
       " '湖',\n",
       " '狐',\n",
       " '壶',\n",
       " '乎',\n",
       " '葫',\n",
       " '乌',\n",
       " '污',\n",
       " '补',\n",
       " '谱',\n",
       " '普',\n",
       " '浦',\n",
       " '部',\n",
       " '簿',\n",
       " '堵',\n",
       " '赌',\n",
       " '杜',\n",
       " '努',\n",
       " '鲁',\n",
       " '橹',\n",
       " '虏',\n",
       " '卤',\n",
       " '祖',\n",
       " '组',\n",
       " '古',\n",
       " '估',\n",
       " '盬',\n",
       " '牯',\n",
       " '股',\n",
       " '鼓',\n",
       " '苦',\n",
       " '五',\n",
       " '伍',\n",
       " '午',\n",
       " '虎',\n",
       " '浒',\n",
       " '户',\n",
       " '沪',\n",
       " '坞',\n",
       " '布',\n",
       " '佈',\n",
       " '怖',\n",
       " '步',\n",
       " '捕',\n",
       " '埠',\n",
       " '暮',\n",
       " '慕',\n",
       " '墓',\n",
       " '募',\n",
       " '妒',\n",
       " '兔',\n",
       " '度',\n",
       " '渡',\n",
       " '镀',\n",
       " '怒',\n",
       " '路',\n",
       " '赂',\n",
       " '露',\n",
       " '鹭',\n",
       " '做',\n",
       " '醋',\n",
       " '措',\n",
       " '素',\n",
       " '诉',\n",
       " '塑',\n",
       " '嗉',\n",
       " '故',\n",
       " '固',\n",
       " '锢',\n",
       " '雇',\n",
       " '顾',\n",
       " '库',\n",
       " '裤',\n",
       " '误',\n",
       " '悟',\n",
       " '戽',\n",
       " '互',\n",
       " '护',\n",
       " '瓠',\n",
       " '庐',\n",
       " '驴',\n",
       " '蛆',\n",
       " '徐',\n",
       " '猪',\n",
       " '除',\n",
       " '储',\n",
       " '初',\n",
       " '锄',\n",
       " '梳',\n",
       " '蔬',\n",
       " '诸',\n",
       " '书',\n",
       " '舒',\n",
       " '如',\n",
       " '居',\n",
       " '墟',\n",
       " '渠',\n",
       " '鱼',\n",
       " '渔',\n",
       " '虚',\n",
       " '嘘',\n",
       " '於',\n",
       " '淤',\n",
       " '余',\n",
       " '馀',\n",
       " '舁',\n",
       " '女',\n",
       " '吕',\n",
       " '稆',\n",
       " '旅',\n",
       " '序',\n",
       " '叙',\n",
       " '绪',\n",
       " '褚',\n",
       " '苎',\n",
       " '阻',\n",
       " '楚',\n",
       " '础',\n",
       " '所',\n",
       " '煮',\n",
       " '杵',\n",
       " '暑',\n",
       " '鼠',\n",
       " '黍',\n",
       " '汝',\n",
       " '举',\n",
       " '巨',\n",
       " '拒',\n",
       " '距',\n",
       " '语',\n",
       " '许',\n",
       " '与',\n",
       " '虑',\n",
       " '滤',\n",
       " '絮',\n",
       " '著',\n",
       " '箸',\n",
       " '助',\n",
       " '庶',\n",
       " '恕',\n",
       " '署',\n",
       " '薯',\n",
       " '据',\n",
       " '锯',\n",
       " '去',\n",
       " '驭',\n",
       " '御',\n",
       " '誉',\n",
       " '预',\n",
       " '豫',\n",
       " '夫',\n",
       " '肤',\n",
       " '跗',\n",
       " '敷',\n",
       " '俘',\n",
       " '孵',\n",
       " '麸',\n",
       " '符',\n",
       " '扶',\n",
       " '芙',\n",
       " '无',\n",
       " '巫',\n",
       " '诬',\n",
       " '趋',\n",
       " '需',\n",
       " '诛',\n",
       " '株',\n",
       " '厨',\n",
       " '雏',\n",
       " '朱',\n",
       " '珠',\n",
       " '枢',\n",
       " '殊',\n",
       " '儒',\n",
       " '拘',\n",
       " '驹',\n",
       " '俱',\n",
       " '区',\n",
       " '驱',\n",
       " '瞿',\n",
       " '愚',\n",
       " '虞',\n",
       " '娱',\n",
       " '吁',\n",
       " '迂',\n",
       " '于',\n",
       " '盂',\n",
       " '榆',\n",
       " '逾',\n",
       " '愉',\n",
       " '府',\n",
       " '腑',\n",
       " '俯',\n",
       " '甫',\n",
       " '斧',\n",
       " '抚',\n",
       " '父',\n",
       " '釜',\n",
       " '腐',\n",
       " '辅',\n",
       " '武',\n",
       " '舞',\n",
       " '侮',\n",
       " '鹉',\n",
       " '缕',\n",
       " '取',\n",
       " '娶',\n",
       " '聚',\n",
       " '拄',\n",
       " '柱',\n",
       " '主',\n",
       " '竖',\n",
       " '乳',\n",
       " '擩',\n",
       " '矩',\n",
       " '雨',\n",
       " '宇',\n",
       " '禹',\n",
       " '羽',\n",
       " '愈',\n",
       " '付',\n",
       " '赋',\n",
       " '傅',\n",
       " '赴',\n",
       " '讣',\n",
       " '附',\n",
       " '务',\n",
       " '雾',\n",
       " '屡',\n",
       " '趣',\n",
       " '驻',\n",
       " '住',\n",
       " '蛀',\n",
       " '铸',\n",
       " '戍',\n",
       " '树',\n",
       " '句',\n",
       " '具',\n",
       " '惧',\n",
       " '遇',\n",
       " '寓',\n",
       " '芋',\n",
       " '喻',\n",
       " '裕',\n",
       " '胎',\n",
       " '苔',\n",
       " '抬',\n",
       " '来',\n",
       " '灾',\n",
       " '栽',\n",
       " '猜',\n",
       " '材',\n",
       " '财',\n",
       " '裁',\n",
       " '鳃',\n",
       " '腮',\n",
       " '该',\n",
       " '开',\n",
       " '碨',\n",
       " '孩',\n",
       " '哀',\n",
       " '埃',\n",
       " '奤',\n",
       " '待',\n",
       " '怠',\n",
       " '殆',\n",
       " '乃',\n",
       " '宰',\n",
       " '彩',\n",
       " '采',\n",
       " '睬',\n",
       " '在',\n",
       " '改',\n",
       " '凯',\n",
       " '海',\n",
       " '亥',\n",
       " '戴',\n",
       " '态',\n",
       " '贷',\n",
       " '代',\n",
       " '袋',\n",
       " '耐',\n",
       " '再',\n",
       " '菜',\n",
       " '棌',\n",
       " '赛',\n",
       " '概',\n",
       " '溉',\n",
       " '慨',\n",
       " '咳',\n",
       " '碍',\n",
       " '爱',\n",
       " '贝',\n",
       " '沛',\n",
       " '带',\n",
       " '太',\n",
       " '泰',\n",
       " '奈',\n",
       " '赖',\n",
       " '癞',\n",
       " '蔡',\n",
       " '盖',\n",
       " '丐',\n",
       " '艾',\n",
       " '害',\n",
       " '蔼',\n",
       " '排',\n",
       " '埋',\n",
       " '豺',\n",
       " '皆',\n",
       " '阶',\n",
       " '秸',\n",
       " '揩',\n",
       " '谐',\n",
       " '挨',\n",
       " '攋',\n",
       " '楷',\n",
       " '骇',\n",
       " '拜',\n",
       " '韛',\n",
       " '介',\n",
       " '界',\n",
       " '芥',\n",
       " '尬',\n",
       " '疥',\n",
       " '届',\n",
       " '戒',\n",
       " '械',\n",
       " '簰',\n",
       " '钗',\n",
       " '柴',\n",
       " '佳',\n",
       " '街',\n",
       " '涯',\n",
       " '崖',\n",
       " '捱',\n",
       " '鞋',\n",
       " '摆',\n",
       " '罢',\n",
       " '买',\n",
       " '奶',\n",
       " '蟹',\n",
       " '矮',\n",
       " '派',\n",
       " '稗',\n",
       " '卖',\n",
       " '债',\n",
       " '晒',\n",
       " '懈',\n",
       " '隘',\n",
       " '败',\n",
       " '迈',\n",
       " '寨',\n",
       " '蔽',\n",
       " '敝',\n",
       " '弊',\n",
       " '币',\n",
       " '毙',\n",
       " '例',\n",
       " '厉',\n",
       " '励',\n",
       " '祭',\n",
       " '际',\n",
       " '穄',\n",
       " '滞',\n",
       " '世',\n",
       " '势',\n",
       " '誓',\n",
       " '逝',\n",
       " '艺',\n",
       " '刈',\n",
       " '蓖',\n",
       " '批',\n",
       " '迷',\n",
       " '低',\n",
       " '堤',\n",
       " '梯',\n",
       " '题',\n",
       " '提',\n",
       " '蹄',\n",
       " '啼',\n",
       " '泥',\n",
       " '犁',\n",
       " '黎',\n",
       " '妻',\n",
       " '脐',\n",
       " '西',\n",
       " '栖',\n",
       " '犀',\n",
       " '鸡',\n",
       " '稽',\n",
       " '溪',\n",
       " '倪',\n",
       " '奚',\n",
       " '兮',\n",
       " '陛',\n",
       " '米',\n",
       " '底',\n",
       " '抵',\n",
       " '体',\n",
       " '弟',\n",
       " '礼',\n",
       " '挤',\n",
       " '荠',\n",
       " '洗',\n",
       " '启',\n",
       " '闭',\n",
       " '箅',\n",
       " '鐾',\n",
       " '谜',\n",
       " '帝',\n",
       " '替',\n",
       " '涕',\n",
       " '剃',\n",
       " '屉',\n",
       " '第',\n",
       " '递',\n",
       " '丽',\n",
       " '隶',\n",
       " '济',\n",
       " '砌',\n",
       " '剂',\n",
       " '细',\n",
       " '婿',\n",
       " '计',\n",
       " '继',\n",
       " '髻',\n",
       " '契',\n",
       " '缢',\n",
       " '翳',\n",
       " '杯',\n",
       " '胚',\n",
       " '坯',\n",
       " '培',\n",
       " '陪',\n",
       " '赔',\n",
       " '裴',\n",
       " '梅',\n",
       " '枚',\n",
       " '媒',\n",
       " '煤',\n",
       " '堆',\n",
       " '推',\n",
       " '雷',\n",
       " '催',\n",
       " '崔',\n",
       " '盔',\n",
       " '魁',\n",
       " '恢',\n",
       " '桅',\n",
       " '灰',\n",
       " '回',\n",
       " '茴',\n",
       " '煨',\n",
       " '倍',\n",
       " '每',\n",
       " '腿',\n",
       " '儡',\n",
       " '罪',\n",
       " '傀',\n",
       " '贿',\n",
       " '悔',\n",
       " '辈',\n",
       " '配',\n",
       " '佩',\n",
       " '焙',\n",
       " '妹',\n",
       " '昧',\n",
       " '对',\n",
       " '碓',\n",
       " '退',\n",
       " '队',\n",
       " '内',\n",
       " '碎',\n",
       " '晦',\n",
       " '溃',\n",
       " '蜕',\n",
       " '兑',\n",
       " '最',\n",
       " '刽',\n",
       " '桧',\n",
       " '外',\n",
       " '绘',\n",
       " '乖',\n",
       " '怀',\n",
       " '槐',\n",
       " '淮',\n",
       " '怪',\n",
       " '蒯',\n",
       " '坏',\n",
       " '歪',\n",
       " '拐',\n",
       " '挂',\n",
       " '卦',\n",
       " '画',\n",
       " '快',\n",
       " '筷',\n",
       " '话',\n",
       " '脆',\n",
       " '岁',\n",
       " '缀',\n",
       " '赘',\n",
       " '税',\n",
       " '芮',\n",
       " '鲑',\n",
       " '卫',\n",
       " '锐',\n",
       " '废',\n",
       " '肺',\n",
       " '吠',\n",
       " '秽',\n",
       " '圭',\n",
       " '闺',\n",
       " '奎',\n",
       " '摧',\n",
       " '畦',\n",
       " '桂',\n",
       " '惠',\n",
       " '慧',\n",
       " '碑',\n",
       " '卑',\n",
       " '披',\n",
       " '皮',\n",
       " '疲',\n",
       " '脾',\n",
       " '弥',\n",
       " '籋',\n",
       " '篱',\n",
       " '璃',\n",
       " '雌',\n",
       " '疵',\n",
       " '斯',\n",
       " '厮',\n",
       " '撕',\n",
       " '知',\n",
       " '蜘',\n",
       " '池',\n",
       " '驰',\n",
       " '枝',\n",
       " '肢',\n",
       " '栀',\n",
       " '眵',\n",
       " '施',\n",
       " '匙',\n",
       " '儿',\n",
       " '奇',\n",
       " '骑',\n",
       " '岐',\n",
       " '宜',\n",
       " '仪',\n",
       " '牺',\n",
       " '移',\n",
       " '彼',\n",
       " '俾',\n",
       " '婢',\n",
       " '靡',\n",
       " '紫',\n",
       " '此',\n",
       " '玺',\n",
       " '徙',\n",
       " '纸',\n",
       " '只',\n",
       " '侈',\n",
       " '舐',\n",
       " '豕',\n",
       " '是',\n",
       " '氏',\n",
       " '尔',\n",
       " '企',\n",
       " '技',\n",
       " '妓',\n",
       " '蚁',\n",
       " '倚',\n",
       " '椅',\n",
       " '臂',\n",
       " '譬',\n",
       " '避',\n",
       " '荔',\n",
       " '刺',\n",
       " '赐',\n",
       " '智',\n",
       " '翅',\n",
       " '豉',\n",
       " '寄',\n",
       " '谊',\n",
       " '义',\n",
       " '议',\n",
       " '戏',\n",
       " '悲',\n",
       " '丕',\n",
       " '琵',\n",
       " '枇',\n",
       " '眉',\n",
       " '楣',\n",
       " '霉',\n",
       " '尼',\n",
       " '梨',\n",
       " '资',\n",
       " '姿',\n",
       " '咨',\n",
       " '瓷',\n",
       " '糍',\n",
       " '私',\n",
       " '迟',\n",
       " '师',\n",
       " '狮',\n",
       " '脂',\n",
       " '肌',\n",
       " '祁',\n",
       " '鳍',\n",
       " '伊',\n",
       " '夷',\n",
       " '姨',\n",
       " '鄙',\n",
       " '比',\n",
       " '秕',\n",
       " '美',\n",
       " '履',\n",
       " '姊',\n",
       " '死',\n",
       " '雉',\n",
       " '旨',\n",
       " '指',\n",
       " '矢',\n",
       " '屎',\n",
       " '秘',\n",
       " '泌',\n",
       " '辔',\n",
       " '庇',\n",
       " '痹',\n",
       " '屁',\n",
       " '备',\n",
       " '鼻',\n",
       " '篦',\n",
       " '媚',\n",
       " '寐',\n",
       " '地',\n",
       " '腻',\n",
       " '利',\n",
       " '痢',\n",
       " '次',\n",
       " '自',\n",
       " '四',\n",
       " '肆',\n",
       " '致',\n",
       " '稚',\n",
       " '至',\n",
       " '示',\n",
       " '视',\n",
       " '嗜',\n",
       " '二',\n",
       " '贰',\n",
       " '冀',\n",
       " '器',\n",
       " '弃',\n",
       " '肄',\n",
       " '厘',\n",
       " '狸',\n",
       " '兹',\n",
       " '滋',\n",
       " '慈',\n",
       " '磁',\n",
       " '司',\n",
       " '丝',\n",
       " '辞',\n",
       " '词',\n",
       " '祠',\n",
       " '痴',\n",
       " '持',\n",
       " '之',\n",
       " '芝',\n",
       " '嗤',\n",
       " '诗',\n",
       " '时',\n",
       " '鲥',\n",
       " '而',\n",
       " '基',\n",
       " '欺',\n",
       " '其',\n",
       " '棋',\n",
       " '期',\n",
       " '旗',\n",
       " '疑',\n",
       " '嬉',\n",
       " '熙',\n",
       " '医',\n",
       " '饴',\n",
       " '你',\n",
       " '李',\n",
       " '理',\n",
       " '鲤',\n",
       " '子',\n",
       " '梓',\n",
       " '似',\n",
       " '祀',\n",
       " '巳',\n",
       " '耻',\n",
       " '痔',\n",
       " '滓',\n",
       " '士',\n",
       " '仕',\n",
       " '柿',\n",
       " '俟',\n",
       " '使',\n",
       " '史',\n",
       " '驶',\n",
       " '止',\n",
       " '趾',\n",
       " '址',\n",
       " '齿',\n",
       " '始',\n",
       " '市',\n",
       " '恃',\n",
       " '耳',\n",
       " '己',\n",
       " '纪',\n",
       " '起',\n",
       " '杞',\n",
       " '拟',\n",
       " '矣',\n",
       " '已',\n",
       " '以',\n",
       " '吏',\n",
       " '字',\n",
       " '牸',\n",
       " '伺',\n",
       " '寺',\n",
       " '嗣',\n",
       " '饲',\n",
       " '置',\n",
       " '治',\n",
       " '厕',\n",
       " '事',\n",
       " '痣',\n",
       " '试',\n",
       " '侍',\n",
       " '饵',\n",
       " '记',\n",
       " '忌',\n",
       " '意',\n",
       " '异',\n",
       " '机',\n",
       " '讥',\n",
       " '祈',\n",
       " '沂',\n",
       " '希',\n",
       " '稀',\n",
       " '衣',\n",
       " '依',\n",
       " '岂',\n",
       " '既',\n",
       " '气',\n",
       " '汽',\n",
       " '毅',\n",
       " '隋',\n",
       " '吹',\n",
       " '炊',\n",
       " '垂',\n",
       " '规',\n",
       " '亏',\n",
       " '窥',\n",
       " '危',\n",
       " '麾',\n",
       " '萎',\n",
       " '嘴',\n",
       " '髓',\n",
       " '揣',\n",
       " '蕊',\n",
       " '诡',\n",
       " '跪',\n",
       " '毁',\n",
       " '委',\n",
       " '睡',\n",
       " '瑞',\n",
       " '伪',\n",
       " '喂',\n",
       " '虽',\n",
       " '绥',\n",
       " '追',\n",
       " '槌',\n",
       " '锤',\n",
       " '衰',\n",
       " '摔',\n",
       " '锥',\n",
       " '谁',\n",
       " '龟',\n",
       " '逵',\n",
       " '葵',\n",
       " '维',\n",
       " '惟',\n",
       " '遗',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 加载数据\n",
    "with open('Data1/data.pkl', 'rb') as f:\n",
    "    data_dict = pickle.load(f)\n",
    "\n",
    "# 使用数据\n",
    "word_list = data_dict['word']\n",
    "initial_list = data_dict['initial']\n",
    "final_1_list = data_dict['final_1']\n",
    "final_2_list = data_dict['final_2']\n",
    "final_3_list = data_dict['final_3']\n",
    "tone_list = data_dict['tone']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从文件 'Data2/dialect_mean_features.npz' 加载数据...\n",
      "计划加载的特征: ['features', 'names']\n",
      "成功加载 2 个特征。\n",
      "正在从文件 'Data2/dialect_slice_mean_features.npz' 加载数据...\n",
      "计划加载的特征: ['features', 'names']\n",
      "成功加载 2 个特征。\n",
      "正在从文件 'Data2/mfcc_gmm_ivectordialect.npz' 加载数据...\n",
      "计划加载的特征: ['features', 'names']\n",
      "成功加载 2 个特征。\n"
     ]
    }
   ],
   "source": [
    "dict_ = load_feats(name='Data2', type='mfcc_dialect_mean')\n",
    "dict_ = load_feats(name='Data2', type='mfcc_slice_mean')\n",
    "dict_ = load_feats(name='Data2', type='mfcc_dialect_gmm_ivector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件中包含的数组（键）: ['features', 'dialect_names']\n",
      "\n",
      "遍历文件中的所有数组:\n",
      "  键名: features, 形状: (17, 400), 数据类型: float64\n",
      "  键名: dialect_names, 形状: (17,), 数据类型: <U5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设您的 .npz 文件名为 'my_data.npz'\n",
    "# file_path = 'Data2/dialect_mean_features.npz' # 替换为您的实际文件路径\n",
    "# 文件中包含的数组（键）: ['features', 'dialect_names']\n",
    "\n",
    "# 遍历文件中的所有数组:\n",
    "#   键名: features, 形状: (17, 39), 数据类型: float32\n",
    "#   键名: dialect_names, 形状: (17,), 数据类型: <U5\n",
    "\n",
    "# file_path = 'Data2/dialect_slice_mean_features.npz'\n",
    "# 文件中包含的数组（键）: ['features', 'slice_names']\n",
    "# 遍历文件中的所有数组:\n",
    "#   键名: features, 形状: (77, 39), 数据类型: float32\n",
    "#   键名: slice_names, 形状: (77,), 数据类型: <U3\n",
    "\n",
    "# file_path = 'Data2/mfcc_gmm_ivectordialect.npz'\n",
    "# 文件中包含的数组（键）: ['features', 'dialect_names']\n",
    "\n",
    "# 遍历文件中的所有数组:\n",
    "#   键名: features, 形状: (17, 400), 数据类型: float64\n",
    "#   键名: dialect_names, 形状: (17,), 数据类型: <U5\n",
    "\n",
    "try:\n",
    "    # 使用 numpy.load() 函数加载 .npz 文件\n",
    "    data = np.load(file_path)\n",
    "\n",
    "    # data 对象类似于一个字典，您可以通过键来访问存储在里面的数组\n",
    "    # 首先，可以查看文件中包含哪些数组（键）\n",
    "    print(\"文件中包含的数组（键）:\", data.files)\n",
    "\n",
    "    # 然后，通过键名来访问具体的数组\n",
    "    # 例如，如果文件中有一个名为 'arr_0' 的数组：\n",
    "    if 'arr_0' in data:\n",
    "        array_0 = data['arr_0']\n",
    "        print(\"\\n数组 'arr_0' 的内容:\")\n",
    "        print(array_0)\n",
    "        print(f\"数组 'arr_0' 的形状: {array_0.shape}\")\n",
    "\n",
    "    # 如果有其他命名的数组，比如 'my_array'：\n",
    "    if 'my_array' in data:\n",
    "        my_named_array = data['my_array']\n",
    "        print(\"\\n数组 'my_array' 的内容:\")\n",
    "        print(my_named_array)\n",
    "        print(f\"数组 'my_array' 的形状: {my_named_array.shape}\")\n",
    "\n",
    "    # 遍历所有数组并打印它们的名字和形状\n",
    "    print(\"\\n遍历文件中的所有数组:\")\n",
    "    for key in data.files:\n",
    "        array_data = data[key]\n",
    "        print(f\"  键名: {key}, 形状: {array_data.shape}, 数据类型: {array_data.dtype}\")\n",
    "\n",
    "    # 使用完毕后，如果您不需要再访问 data 对象，可以关闭它（虽然对于 .npz，通常不是严格必须的，\n",
    "    # 因为数据已经加载到内存，但这是一个好习惯，特别是对于其他类型的文件对象）\n",
    "    data.close()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：文件 {file_path} 未找到。\")\n",
    "except Exception as e:\n",
    "    print(f\"读取文件时发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graduation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
